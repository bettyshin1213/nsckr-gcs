# ğŸš— GCS: GETCHA Scraper  

> **Automated Web Scraper for Imported Car Discounts**  
> A Python-based scraper that collects daily discount data from the **GETCHA Mobile Website** and exports it into Excel for analysis.  
> This project replaces manual data gathering and provides **real-time competitive insights** for business and marketing teams.  

---

# ğŸ“„ Overview 

<img width="1033" height="553" alt="image" src="https://github.com/user-attachments/assets/dce4a7e7-deb5-4f1c-92b1-7701bed60849" />
<img width="1001" height="553" alt="image" src="https://github.com/user-attachments/assets/2e6f4441-1e8b-42bb-a096-85efa32758d9" />

---

## ğŸ¯ Goals
- Automate the collection of car discount data (BMW, Mini, MB, Audi, VW).  
- Ensure **daily monitoring** of both BMW and competitorsâ€™ pricing strategies.  
- Minimize human error and reduce manual workload.  
- Provide structured Excel outputs for further analysis.  

---

## âœ¨ Key Features
- ğŸ” **Brand Series Exploration** â€“ Automatically browses each brandâ€™s series.  
- ğŸ’° **Discount Collection** â€“ MSRP, cash discounts, and finance discounts.  
- â›½ **Fuel & Year Detection** â€“ Extracts fuel type (P, D, BEV, PHEV) and model year.  
- ğŸ”„ **Duplicate Prevention** â€“ Avoids scraping the same series more than once per day.  
- ğŸ“Š **Excel Export** â€“ Saves as `car_data_YYYYMMDD.xlsx`.  
- ğŸ“œ **Logging & Error Handling** â€“ Tracks events in `scraping.log`.  

---

## ğŸ“‚ Data Scope
- **Brands**: BMW, Mini, Mercedes-Benz, Audi, Volkswagen  
- **Fields**:  
  - Scraped Date  
  - Model Name / Series  
  - Model Year  
  - Fuel Type  
  - MSRP (Manufacturerâ€™s Suggested Retail Price)  
  - Cash Discount / Finance Discount  

---

## âš’ï¸ Installation

1. Clone the repository:
   ```
   git clone https://atc-github.azure.cloud.bmw/nsckrit/nsckr-autoscrap.git
   ```

2. Start a program: [`run-autoscrap.bat`] (located in the project directory).

---

## âš™ï¸ Usage

1. Ensure you have the necessary web drivers installed for Selenium (e.g., ChromeDriver for Google Chrome).
2. Update the `urls.json` file in src directory with the URLs you want to scrape.

---

## ğŸ“¦ Example Output

car_data_20250625.xlsx
scraping.log


---

## ğŸš€ Future Improvements
	â€¢	â˜ï¸ Migrate to AWS Lambda.
	â€¢	ğŸ”§ Integrate with MCP for lifecycle management.
